# AI
## Artificial Intelligence Notes

---

### From Age of Information to Age of Understanding

| AOI | AOU |
|---|---|
| Information | Understanding |
| Mechanistic | Humanistic |
| Single Interaction | Conversational |
| We Synthesize | AI Synthesizes |
| We conform to computers | Computer conform to us |
| Content created by humans | Content created by computers |
| Wrought memorization | External facts and references |
| Dissociative | Relational |

### LLM (Large Language Model)

A large language model (LLM) is a language model consisting of a neural network with many parameters (typically billions of weights or more), trained on large quantities of unlabelled text using self-supervised learning. LLMs emerged around 2018 and perform well at a wide variety of tasks. This has shifted the focus of natural language processing research away from the previous paradigm of training specialized supervised models for specific tasks.

Though the term large language model has no formal definition, it generally refers to deep learning models having a parameter count on the order of billions or more. LLMs are general purpose models which excel at a wide range of tasks, as opposed to being trained for one specific task (such as sentiment analysis, named entity recognition, or mathematical reasoning). Though trained on simple tasks along the lines of predicting the next word in a sentence, neural language models with sufficient training and parameter counts are found to capture much of the syntax and semantics of human language. In addition, large language models demonstrate considerable general knowledge about the world, and are able to "memorize" a great quantity of facts during training.

